# [WACV2026] AEON: Adaptive Embedding Optimized Noise for Robust Watermarking in Diffusion Models

This repository contains the official PyTorch implementation of our **AEON** paper:  
# ğŸŒŠÂ **"AEON: Adaptive Embedding Optimized Noise for Robust Watermarking in Diffusion Models"**  

---

> **Abstract:**  
*The widespread use of synthetic image generation models and the challenges associated with authenticity preservation have fueled the demand for robust watermarking methods to safeguard authenticity and protect the copyright of synthetic images. Existing watermarking methods embed. Invisible signatures in synthetic images often compromise image quality and remain susceptible to multiple watermark removal attacks, including reconstruction and forgery methods. To overcome this issue, we propose a novel watermarking approach,~\SystemName, which seamlessly integrates the watermark into the latent diffusion process and ensures the watermark aligns with scene semantics in the final image. Unlike existing invisible in-diffusion watermarking and traditional hash-based methods, our approach adapts the neural synthesized hash-based watermark to the semantics of the generated image during the intermediate diffusion process instead of embedding traditional hashes with the initial noise. This facilitates visual coherence in the generated image while enhancing adversarial robustness and resilience against single or multiple adversarial and traditional watermark removal attacks. Our proposed approach a) modulates the noise sampling in each diffusion denoising iteration through a learnable watermark embedding, b) optimizes consistency, reconstruction, and similarity loss, enforcing local and global alignment between the watermark structure and the underlying image content, and c) generates a strong watermark by allowing late embedding of the watermark in the diffusion process. Empirical results demonstrate the effectiveness of the proposed approach in retaining quality and its robustness against cumulative adversarial attacks.*

---

## âœ¨Â Key Features
- **Semantic, adaptive watermarking.**Â AEON injects a *learnable* hashâ€‘based noise into the latent at runâ€‘time so the watermark aligns with the sceneâ€™s semantics while remaining invisible.  
- **Hashâ€‘networkâ€‘driven noise generation.**Â A dedicated network produces frequencyâ€‘domain watermark noise that stays close to the latent structure, minimising quality loss.  
- **Lateâ€‘stage injection without artifacts.**Â Because the watermark is adaptive, it can be embedded as late as stepâ€¯40, yielding PSNRâ€¯â‰ˆâ€¯25.9â€¯dB with <â€¯1â€¯% AUC drop after cumulative attacks.  
- **Stateâ€‘ofâ€‘theâ€‘art robustness.**Â Across blur, noise, JPEG, crop, rotation and reconstruction attacks, AEON achieves an average AUC ofâ€¯0.994 on Stableâ€¯Diffusionâ€”outperforming Treeâ€‘Ring, ROBIN, WIND and others.  
- **Straightâ€‘through training endâ€‘toâ€‘end.**Â The binary hash layer is trained with a straightâ€‘through estimator, so gradients flow through the discretisation step (details in Sectionâ€¯3 of the paper).  
- **Easy verification.**Â A reverse DDIM pass to *t*<sub>inject</sub> plus an FFT on selected bins delivers a oneâ€‘shot match/noâ€‘match decision.

---

## ğŸ› ï¸Â Architecture at a Glance

---



Stageâ€¯1  (Training)   : Hash network learns semantic noise in fÂ â€‘space.
Stageâ€¯2  (Generation) : Adaptive hash blended into latent via FFT/IFFT.
Stageâ€¯3  (Verification): Reverse DDIMÂ +Â FFT recovers watermark bits.

AEON first trains a hashing network on intermediate noise, then blends its output into the latent via FFT/IFFT, and finally verifies by partially reversing the diffusion.

<p align="center">
  <img src="assets/aeon_pipeline.png" width="650" alt="AEON threeâ€‘stage pipeline">
</p>

---

## ğŸ“Â DatasetÂ & Experimental Setup

| Purpose              | Details                                                                             |
|----------------------|-------------------------------------------------------------------------------------|
| Hashâ€‘net training    | **MSâ€‘COCO** images + 1â€¯000 captions from Gustavostaâ€™s *Stableâ€‘Diffusionâ€‘Prompts*    |
| Diffusion backbone   | Stableâ€¯DiffusionÂ v2.1 (50 DDIM steps, guidanceâ€¯7.5)                                 |
| Hardware             | 1Ã—Â NVIDIAÂ A100Â 40â€¯GB                                                                |
| Hyperâ€‘parameters     | LRÂ 5eâ€‘4 Â· batchÂ 1 Â· 2â€¯000â€¯steps Â· Î±Â 0.9 Â· Î³Â 0.4                                     |

---

## ğŸš€Â Training / Inference Pipeline

### 1â€¯. Train the Hashing Network
```bash
bash train_aeon.sh


## ğŸš€ Injection Pipeline
bash inject_adaptive.sh


### 3. Inference
```bash
bash inference.sh

```
## ğŸ“Š Headline Results (StableÂ Diffusion)

| Attack | Clean | Blur | Noise | JPEG | Rotation | Crop | **Avg** |
|--------|------:|-----:|------:|-----:|---------:|-----:|--------:|
| **AUC** | 1.000 | 1.000 | 0.986 | 1.000 | 0.985 | 0.998 | **0.994** |

| Model      | PSNRÂ â†‘ | SSIMÂ â†‘ | MSSIMÂ â†‘ | FIDÂ â†“ |
|------------|-------:|-------:|--------:|------:|
| Treeâ€‘Ring  | 15.37  | 0.568  | 0.626   | 25.93 |
| ROBIN      | 24.03  | 0.768  | 0.881   | 26.86 |
| **AEON**   | **25.93** | **0.812** | **0.918** | **26.61** |

---

## ğŸ”¬Â AblationÂ â€” Effect of *t*<sub>inject</sub>

| Step | PSNRÂ â†‘ | AUC (postâ€‘attack)Â â†‘ |
|------|-------:|--------------------:|
| 10   | 19.63  | 0.665 |
| 20   | 20.96  | 0.762 |
| 35   | 24.35  | 0.981 |
| **40** | **25.93** | **0.991** |
